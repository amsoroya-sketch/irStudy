<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Free Medical Resources Setup Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-radius: 8px;
        }

        /* Navigation Breadcrumbs */
        .breadcrumbs {
            background: #2c3e50;
            color: white;
            padding: 15px 20px;
            margin: -40px -40px 30px -40px;
            border-radius: 8px 8px 0 0;
            font-size: 14px;
        }

        .breadcrumbs a {
            color: #3498db;
            text-decoration: none;
            margin-right: 5px;
        }

        .breadcrumbs a:hover {
            text-decoration: underline;
        }

        .breadcrumbs span {
            margin: 0 8px;
            color: #95a5a6;
        }

        /* Quick Navigation */
        .quick-nav {
            background: #ecf0f1;
            padding: 20px;
            margin-bottom: 30px;
            border-left: 4px solid #3498db;
            border-radius: 4px;
        }

        .quick-nav h3 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 18px;
        }

        .quick-nav ul {
            list-style: none;
        }

        .quick-nav li {
            margin: 8px 0;
        }

        .quick-nav a {
            color: #2980b9;
            text-decoration: none;
            padding: 5px 0;
            display: inline-block;
        }

        .quick-nav a:hover {
            color: #3498db;
            text-decoration: underline;
        }

        /* Headers */
        h1 {
            color: #2c3e50;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 3px solid #3498db;
            font-size: 2.5em;
        }

        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #bdc3c7;
            font-size: 1.8em;
        }

        h3 {
            color: #34495e;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.4em;
        }

        h4 {
            color: #34495e;
            margin-top: 25px;
            margin-bottom: 12px;
            font-size: 1.2em;
        }

        /* Paragraphs and Lists */
        p {
            margin-bottom: 15px;
            line-height: 1.8;
        }

        ul, ol {
            margin: 15px 0 15px 30px;
        }

        li {
            margin: 8px 0;
            line-height: 1.8;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 14px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        th {
            background: #3498db;
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: 600;
        }

        td {
            padding: 12px;
            border-bottom: 1px solid #ddd;
        }

        tr:hover {
            background: #f5f5f5;
        }

        /* Code Blocks */
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #c7254e;
        }

        pre {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
        }

        pre code {
            background: none;
            color: #ecf0f1;
            padding: 0;
        }

        /* Blockquotes */
        blockquote {
            border-left: 4px solid #3498db;
            padding-left: 20px;
            margin: 20px 0;
            color: #555;
            font-style: italic;
            background: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        /* Medical Alert Boxes */
        .alert {
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 5px;
            border-left: 5px solid;
        }

        .alert-red {
            background: #fee;
            border-color: #e74c3c;
            color: #c0392b;
        }

        .alert-yellow {
            background: #ffeaa7;
            border-color: #f39c12;
            color: #d68910;
        }

        .alert-green {
            background: #d5f4e6;
            border-color: #27ae60;
            color: #1e8449;
        }

        .alert-blue {
            background: #d6eaf8;
            border-color: #3498db;
            color: #21618c;
        }

        /* Links */
        a {
            color: #2980b9;
            text-decoration: none;
        }

        a:hover {
            color: #3498db;
            text-decoration: underline;
        }

        /* Footer */
        .footer {
            margin-top: 50px;
            padding-top: 20px;
            border-top: 2px solid #ecf0f1;
            text-align: center;
            color: #7f8c8d;
            font-size: 14px;
        }

        /* Checkboxes */
        input[type="checkbox"] {
            margin-right: 8px;
        }

        /* Print styles */
        @media print {
            body {
                background: white;
                padding: 0;
            }
            .container {
                box-shadow: none;
                padding: 20px;
            }
            .breadcrumbs {
                display: none;
            }
            .quick-nav {
                display: none;
            }
        }

        /* Responsive */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            h1 {
                font-size: 2em;
            }
            h2 {
                font-size: 1.5em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="breadcrumbs">
<a href="/home/dev/Development/irStudy/MASTER_INDEX.html">üè† Home</a>
<span>‚Üí</span>
<span>/</span>
<span>‚Üí</span>
<span>docs</span>
</div>
        
        <h1>Free Medical Resources Setup Guide</h1>
<h2>Download, Process, and Integrate Free Medical Content</h2>

<strong>Last Updated:</strong> December 14, 2025
<strong>Purpose:</strong> Complete guide to acquiring and setting up FREE medical resources for your AI system

<strong>Zero Cost ‚úÖ | High Quality ‚úÖ | Legal ‚úÖ</strong>

<hr>

<h2>üìã Table of Contents</h2>

<ol>
<li><a href="#1-statpearls">StatPearls</a></li>
<li><a href="#2-ncbi-bookshelf">NCBI Bookshelf</a></li>
<li><a href="#3-pubmed-central">PubMed Central</a></li>
<li><a href="#4-australian-government-guidelines">Australian Government Guidelines</a></li>
<li><a href="#5-who-guidelines">WHO Guidelines</a></li>
<li><a href="#6-openstax-medical">OpenStax Medical</a></li>
<li><a href="#7-clinical-calculators--tools">Clinical Calculators & Tools</a></li>
<li><a href="#8-automation-scripts">Automation Scripts</a></li>
<p>
</ol>
</p>

<hr>

<h2>1. StatPearls</h2>

<strong>URL:</strong> https://www.ncbi.nlm.nih.gov/books/NBK430685/
<strong>Content:</strong> 10,000+ medical articles covering all specialties
<strong>Format:</strong> HTML (can convert to PDF)
<strong>Quality:</strong> ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent (peer-reviewed, regularly updated)
<strong>Cost:</strong> FREE

<h3>What is StatPearls?</h3>

<p>
StatPearls is a comprehensive medical encyclopedia with:
</p>
<ul>
<li>10,000+ articles</li>
<li>All medical specialties covered</li>
<li>Peer-reviewed content</li>
<li>Regular updates (quarterly)</li>
<li>No registration required</li>
<p>
</ul>
</p>

<h3>How to Download StatPearls</h3>

<h4>Option 1: Manual Download (Individual Articles)</h4>

<pre><code><h1>1. Visit StatPearls</h1>
<p>
https://www.ncbi.nlm.nih.gov/books/NBK430685/
</p>

<h1>2. Browse by specialty or search</h1>
<h1>3. Click on any article</h1>
<h1>4. Right-click ‚Üí Save As ‚Üí PDF</h1>
<h1>Or use browser's Print ‚Üí Save as PDF</h1>
<p>
</code></pre>
</p>

<h4>Option 2: Bulk Download Script (Python)</h4>

<p>
Create this script: <code>scripts/download_statpearls.py</code>
</p>

<pre><code>#!/usr/bin/env python3
<p>
"""
Download StatPearls articles in bulk
"""
</p>

<p>
import requests
from bs4 import BeautifulSoup
import time
from pathlib import Path
import pdfkit  # Requires wkhtmltopdf installed
</p>

<h1>Configuration</h1>
<p>
OUTPUT_DIR = Path("data/pdfs/free/statpearls")
BASE_URL = "https://www.ncbi.nlm.nih.gov"
STATPEARLS<em>HOME = f"{BASE</em>URL}/books/NBK430685/"
</p>

<h1>Specialties to download</h1>
<p>
SPECIALTIES = [
    "cardiology",
    "respiratory",
    "gastroenterology",
    "endocrinology",
    "neurology",
    "psychiatry",
    "pediatrics",
    "obstetrics",
    "surgery",
    "<span style="color: #e74c3c; font-weight: bold;">‚ö†Ô∏è EMERGENCY</span>-medicine"
]
</p>

<p>
def get<em>article</em>links(specialty<em>page</em>url):
    """Get all article links from a specialty page"""
    response = requests.get(specialty<em>page</em>url)
    soup = BeautifulSoup(response.content, 'html.parser')
</p>

<p>
    links = []
    for link in soup.find_all('a', href=True):
        href = link['href']
        if '/books/NBK' in href:
            full<em>url = BASE</em>URL + href if not href.startswith('http') else href
            links.append(full_url)
</p>

<p>
    return list(set(links))  # Remove duplicates
</p>

<p>
def download<em>article</em>as<em>pdf(url, output</em>path):
    """Download article and convert to PDF"""
    try:
        # Get article HTML
        response = requests.get(url)
</p>

<p>
        # Convert to PDF using pdfkit
        pdfkit.from<em>string(response.text, str(output</em>path))
</p>

<p>
        print(f"‚úì Downloaded: {output_path.name}")
        return True
    except Exception as e:
        print(f"‚úó Failed: {url} - {e}")
        return False
</p>

<p>
def main():
    # Create output directory
    OUTPUT<em>DIR.mkdir(parents=True, exist</em>ok=True)
</p>

<p>
    print("üìö StatPearls Bulk Downloader")
    print(f"Output: {OUTPUT_DIR}")
    print()
</p>

<p>
    # Get all articles
    print("Fetching article list...")
    response = requests.get(STATPEARLS_HOME)
    soup = BeautifulSoup(response.content, 'html.parser')
</p>

<p>
    # Find all article links
    article_links = []
    for link in soup.find_all('a', href=True):
        href = link['href']
        if '/books/NBK' in href and href != '/books/NBK430685/':
            full<em>url = BASE</em>URL + href if not href.startswith('http') else href
            article<em>links.append(full</em>url)
</p>

<p>
    article<em>links = list(set(article</em>links))
    print(f"Found {len(article_links)} articles")
</p>

<p>
    # Download each article
    downloaded = 0
    failed = 0
</p>

<p>
    for i, url in enumerate(article_links, 1):
        # Extract article ID
        article_id = url.split('/books/')[1].split('/')[0]
        output<em>file = OUTPUT</em>DIR / f"{article_id}.pdf"
</p>

<p>
        # Skip if already downloaded
        if output_file.exists():
            print(f"‚äò Skipped (exists): {output_file.name}")
            continue
</p>

<p>
        # Download
        print(f"[{i}/{len(article<em>links)}] Downloading {article</em>id}...")
        if download<em>article</em>as<em>pdf(url, output</em>file):
            downloaded += 1
        else:
            failed += 1
</p>

<p>
        # Rate limiting (be nice to NCBI servers)
        time.sleep(2)
</p>

<p>
    print()
    print("="*60)
    print(f"‚úì Downloaded: {downloaded}")
    print(f"‚úó Failed: {failed}")
    print(f"üìÅ Location: {OUTPUT_DIR}")
    print("="*60)
</p>

<p>
if <strong>name</strong> == "<strong>main</strong>":
    main()
</code></pre>
</p>

<strong>Dependencies:</strong>
<pre><code>pip install requests beautifulsoup4 pdfkit
<h1>Also install wkhtmltopdf:</h1>
<h1>Ubuntu/Debian: sudo apt-get install wkhtmltopdf</h1>
<h1>macOS: brew install wkhtmltopdf</h1>
<h1>Windows: Download from https://wkhtmltopdf.org/downloads.html</h1>
<p>
</code></pre>
</p>

<strong>Run:</strong>
<pre><code>python scripts/download_statpearls.py
<p>
</code></pre>
</p>

<h4>Option 3: Use Official API (Advanced)</h4>

<pre><code>from Bio import Entrez

<h1>Set your email (NCBI requirement)</h1>
<p>
Entrez.email = "your_email@example.com"
</p>

<h1>Search StatPearls</h1>
<p>
handle = Entrez.esearch(db="books", term="statpearls")
record = Entrez.read(handle)
handle.close()
</p>

<h1>Fetch full text</h1>
<p>
for book_id in record["IdList"]:
    handle = Entrez.efetch(db="books", id=book_id, rettype="full", retmode="text")
    content = handle.read()
    handle.close()
</p>

<p>
    # Save to file
    with open(f"data/pdfs/free/statpearls/{book_id}.txt", "w") as f:
        f.write(content)
</code></pre>
</p>

<h3>Processing StatPearls Through Your Pipeline</h3>

<pre><code><h1>1. Download StatPearls</h1>
<p>
python scripts/download_statpearls.py
</p>

<h1>2. Process through your pipeline</h1>
<p>
./medical_ai.py process pdfs --input data/pdfs/free/statpearls
</p>

<h1>3. Verify Qdrant indexing</h1>
<p>
./medical_ai.py test search "acute coronary syndrome"
</code></pre>
</p>

<hr>

<h2>2. NCBI Bookshelf</h2>

<strong>URL:</strong> https://www.ncbi.nlm.nih.gov/books/
<strong>Content:</strong> 2,000+ biomedical books
<strong>Format:</strong> HTML, PDF (some books)
<strong>Cost:</strong> FREE

<h3>Available Medical Textbooks</h3>

<ol>
<li><strong>Harrison's Principles of Internal Medicine</strong> (select chapters, older editions)</li>
<li><strong>Basic and Clinical Pharmacology</strong> (Katzung)</li>
<li><strong>Medical Microbiology</strong> (Baron)</li>
<li><strong>Clinical Methods</strong> (Walker)</li>
<li><strong>The Merck Manual</strong> (older editions)</li>
<li><strong>Many NIH/CDC guidelines</strong></li>
<p>
</ol>
</p>

<h3>How to Download</h3>

<h4>Browse and Download</h4>

<pre><code><h1>Visit NCBI Bookshelf</h1>
<p>
https://www.ncbi.nlm.nih.gov/books/
</p>

<h1>Filter by subject:</h1>
<ul>
<li>Medicine</li>
<li>Surgery</li>
<li>Pediatrics</li>
<li>etc.</li>
<p>
</ul>
</p>

<h1>Click on a book ‚Üí Download ‚Üí PDF (if available)</h1>
<p>
</code></pre>
</p>

<h4>Bulk Download Script</h4>

<pre><code>#!/usr/bin/env python3
<p>
"""Download NCBI Bookshelf books"""
</p>

<p>
from Bio import Entrez
from pathlib import Path
import time
</p>

<p>
Entrez.email = "your_email@example.com"
OUTPUT<em>DIR = Path("data/pdfs/free/ncbi</em>bookshelf")
OUTPUT<em>DIR.mkdir(parents=True, exist</em>ok=True)
</p>

<h1>Search for medical books</h1>
<p>
handle = Entrez.esearch(db="books", term="medicine[filter]", retmax=100)
record = Entrez.read(handle)
handle.close()
</p>

<p>
print(f"Found {len(record['IdList'])} books")
</p>

<p>
for book_id in record['IdList']:
    try:
        # Fetch book metadata
        handle = Entrez.esummary(db="books", id=book_id)
        summary = Entrez.read(handle)
        handle.close()
</p>

<p>
        title = summary[0]['Title']
        print(f"Downloading: {title}")
</p>

<p>
        # Fetch full text
        handle = Entrez.efetch(db="books", id=book_id, rettype="full", retmode="text")
        content = handle.read()
        handle.close()
</p>

<p>
        # Save
        filename = f"{book<em>id}</em>{title[:50].replace(' ', '_')}.txt"
        output<em>file = OUTPUT</em>DIR / filename
</p>

<p>
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
</p>

<p>
        print(f"‚úì Saved: {filename}")
        time.sleep(1)  # Rate limiting
</p>

<p>
    except Exception as e:
        print(f"‚úó Failed {book_id}: {e}")
</p>

<p>
print(f"\nüìÅ Downloaded to: {OUTPUT_DIR}")
</code></pre>
</p>

<hr>

<h2>3. PubMed Central</h2>

<strong>URL:</strong> https://www.ncbi.nlm.nih.gov/pmc/
<strong>Content:</strong> 10+ million free full-text articles
<strong>Format:</strong> HTML, PDF, XML
<strong>Cost:</strong> FREE

<h3>What is PubMed Central?</h3>

<ul>
<li>10+ million free full-text biomedical articles</li>
<li>Latest research and reviews</li>
<li>Systematic reviews and meta-analyses</li>
<li>Clinical guidelines</li>
<p>
</ul>
</p>

<h3>Download Medical Review Articles</h3>

<pre><code>#!/usr/bin/env python3
<p>
"""Download PubMed Central review articles on key medical topics"""
</p>

<p>
from Bio import Entrez
from pathlib import Path
import time
</p>

<p>
Entrez.email = "your_email@example.com"
OUTPUT<em>DIR = Path("data/pdfs/free/pubmed</em>central")
OUTPUT<em>DIR.mkdir(parents=True, exist</em>ok=True)
</p>

<h1>Topics to search</h1>
<p>
TOPICS = [
    "acute coronary syndrome[Title]",
    "heart failure management[Title]",
    "diabetes mellitus treatment[Title]",
    "asthma guidelines[Title]",
    "hypertension management[Title]",
    # Add more topics...
]
</p>

<p>
for topic in TOPICS:
    print(f"\nSearching: {topic}")
</p>

<p>
    # Search for review articles
    query = f"{topic} AND Review[ptyp] AND free fulltext[filter]"
    handle = Entrez.esearch(db="pmc", term=query, retmax=20)
    record = Entrez.read(handle)
    handle.close()
</p>

<p>
    print(f"Found {len(record['IdList'])} articles")
</p>

<p>
    for pmc_id in record['IdList']:
        try:
            # Fetch article
            handle = Entrez.efetch(db="pmc", id=pmc_id, rettype="full", retmode="xml")
            article_xml = handle.read()
            handle.close()
</p>

<p>
            # Save
            output<em>file = OUTPUT</em>DIR / f"PMC{pmc_id}.xml"
            with open(output_file, 'wb') as f:
                f.write(article_xml)
</p>

<p>
            print(f"  ‚úì Downloaded PMC{pmc_id}")
            time.sleep(0.5)
</p>

<p>
        except Exception as e:
            print(f"  ‚úó Failed PMC{pmc_id}: {e}")
</p>

<p>
print(f"\nüìÅ Downloaded to: {OUTPUT_DIR}")
</code></pre>
</p>

<h3>Convert PMC XML to Text</h3>

<pre><code>from Bio import Entrez
<p>
from bs4 import BeautifulSoup
</p>

<p>
def pmc<em>xml</em>to<em>text(xml</em>content):
    """Extract text from PubMed Central XML"""
    soup = BeautifulSoup(xml_content, 'xml')
</p>

<p>
    # Extract title
    title = soup.find('article-title')
    title<em>text = title.get</em>text() if title else "Unknown"
</p>

<p>
    # Extract abstract
    abstract = soup.find('abstract')
    abstract<em>text = abstract.get</em>text() if abstract else ""
</p>

<p>
    # Extract body
    body = soup.find('body')
    body<em>text = body.get</em>text() if body else ""
</p>

<p>
    # Combine
    full<em>text = f"# {title</em>text}\n\n## Abstract\n{abstract<em>text}\n\n## Full Text\n{body</em>text}"
</p>

<p>
    return full_text
</code></pre>
</p>

<hr>

<h2>4. Australian Government Guidelines</h2>

<strong>Cost:</strong> FREE
<strong>Quality:</strong> ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (official government sources)
<strong>Format:</strong> PDF, HTML

<h3>Available Resources</h3>

<h4>1. Therapeutic Guidelines (Institutional Access)</h4>

<strong>URL:</strong> https://tgldcdp.tg.org.au/
<strong>Cost:</strong> FREE if you have hospital/university access

<strong>Check if you have access:</strong>
<ul>
<li>Australian hospital employee</li>
<li>Australian medical student</li>
<li>University library access</li>
<p>
</ul>
</p>

<strong>How to download:</strong>
<ol>
<li>Log in via institutional access</li>
<li>Browse to topic</li>
<li>Download PDF chapter</li>
<p>
</ol>
</p>

<h4>2. NSW Health Clinical Guidelines</h4>

<strong>URL:</strong> https://www1.health.nsw.gov.au/pds/Pages/pds-by-topic.aspx
<strong>Cost:</strong> FREE (all PDFs)

<strong>Download script:</strong>

<pre><code>#!/bin/bash
<h1>Download NSW Health Clinical Guidelines</h1>

<p>
OUTPUT<em>DIR="data/pdfs/free/nsw</em>health"
mkdir -p "$OUTPUT_DIR"
</p>

<h1>List of key guidelines (add more as needed)</h1>
<p>
GUIDELINES=(
    "https://www1.health.nsw.gov.au/pds/ActivePDSDocuments/GL2018_020.pdf"  # Acute Coronary Syndrome
    "https://www1.health.nsw.gov.au/pds/ActivePDSDocuments/GL2017_001.pdf"  # Asthma
    "https://www1.health.nsw.gov.au/pds/ActivePDSDocuments/GL2015_010.pdf"  # Diabetes
    # Add more URLs...
)
</p>

<p>
for url in "${GUIDELINES[@]}"; do
    filename=$(basename "$url")
    echo "Downloading $filename..."
    wget -O "$OUTPUT_DIR/$filename" "$url"
    sleep 1
done
</p>

<p>
echo "‚úì Downloaded to $OUTPUT_DIR"
</code></pre>
</p>

<h4>3. National Asthma Handbook</h4>

<strong>URL:</strong> https://www.asthmahandbook.org.au/
<strong>Cost:</strong> FREE
<strong>Format:</strong> Online (can print to PDF)

<strong>Download:</strong>
<pre><code><h1>Visit each section and save as PDF</h1>
<h1>Or use wget to download entire site:</h1>
<p>
wget --recursive --no-parent --convert-links \
     --page-requisites --adjust-extension \
     https://www.asthmahandbook.org.au/
</code></pre>
</p>

<h4>4. Australian Immunisation Handbook</h4>

<strong>URL:</strong> https://immunisationhandbook.health.gov.au/
<strong>Cost:</strong> FREE
<strong>Format:</strong> PDF download available

<pre><code><h1>Download full handbook</h1>
<p>
wget -O data/pdfs/free/australian<em>immunisation</em>handbook.pdf \
     https://immunisationhandbook.health.gov.au/resources/handbook
</code></pre>
</p>

<h4>5. RACGP Guidelines</h4>

<strong>URL:</strong> https://www.racgp.org.au/clinical-resources/clinical-guidelines
<strong>Cost:</strong> FREE (most guidelines)

<strong>Key Guidelines:</strong>
<ul>
<li>Red Book (Guidelines for preventive activities)</li>
<li>Management of type 2 diabetes</li>
<li>Smoking cessation</li>
<li>Alcohol problems</li>
<p>
</ul>
</p>

<hr>

<h2>5. WHO Guidelines</h2>

<strong>URL:</strong> https://www.who.int/publications/guidelines
<strong>Content:</strong> International clinical guidelines
<strong>Cost:</strong> FREE

<h3>Key WHO Guidelines for Medical Education</h3>

<ol>
<li><strong>Essential Medicines List</strong></li>
<li><strong>Vaccination Guidelines</strong></li>
<li><strong>Disease-specific protocols (TB, HIV, Malaria)</strong></li>
<li><strong><span style="color: #e74c3c; font-weight: bold;">‚ö†Ô∏è EMERGENCY</span> care guidelines</strong></li>
<p>
</ol>
</p>

<h3>Download WHO Guidelines</h3>

<pre><code>#!/usr/bin/env python3
<p>
"""Download WHO Guidelines"""
</p>

<p>
import requests
from pathlib import Path
</p>

<p>
OUTPUT<em>DIR = Path("data/pdfs/free/who</em>guidelines")
OUTPUT<em>DIR.mkdir(parents=True, exist</em>ok=True)
</p>

<h1>List of WHO guideline URLs (find these on WHO website)</h1>
<p>
GUIDELINES = [
    {
        "name": "WHO<em>Essential</em>Medicines_List",
        "url": "https://www.who.int/publications/i/item/WHO-MHP-HPS-EML-2023.02"
    },
    # Add more...
]
</p>

<p>
for guideline in GUIDELINES:
    print(f"Downloading: {guideline['name']}")
</p>

<p>
    response = requests.get(guideline['url'])
</p>

<p>
    if response.status_code == 200:
        output<em>file = OUTPUT</em>DIR / f"{guideline['name']}.pdf"
        with open(output_file, 'wb') as f:
            f.write(response.content)
        print(f"‚úì Saved: {output_file}")
    else:
        print(f"‚úó Failed: {guideline['name']}")
</code></pre>
</p>

<hr>

<h2>6. OpenStax Medical</h2>

<strong>URL:</strong> https://openstax.org/subjects/science
<strong>Content:</strong> Free open-source textbooks
<strong>Cost:</strong> FREE
<strong>License:</strong> Creative Commons (CC-BY)

<h3>Available Medical Books</h3>

<ol>
<li><strong>Anatomy & Physiology</strong> (2,000+ pages)</li>
<li><strong>Biology 2e</strong> (comprehensive biology)</li>
<li><strong>Chemistry</strong> (for biochemistry foundation)</li>
<li><strong>Microbiology</strong></li>
<p>
</ol>
</p>

<h3>Download OpenStax Books</h3>

<pre><code><h1>Visit OpenStax</h1>
<p>
https://openstax.org/subjects/science
</p>

<h1>For each book:</h1>
<h1>1. Click "Get this book"</h1>
<h1>2. Download PDF (completely free, no registration)</h1>

<h1>Example: Anatomy & Physiology</h1>
<p>
wget -O data/pdfs/free/openstax<em>anatomy</em>physiology.pdf \
     https://openstax.org/downloads/anatomy-and-physiology.pdf
</code></pre>
</p>

<hr>

<h2>7. Clinical Calculators & Tools</h2>

<strong>These provide additional medical data for your system</strong>

<h3>Medical Calculator Databases</h3>

<h4>1. MDCalc</h4>

<strong>URL:</strong> https://www.mdcalc.com/
<strong>Content:</strong> 500+ clinical calculators
<strong>API:</strong> Available (check for terms of use)

<strong>Calculators include:</strong>
<ul>
<li>CURB-65 (pneumonia severity)</li>
<li>CHA2DS2-VASc (stroke risk in AF)</li>
<li>HEART Score (chest pain)</li>
<li>Wells Score (DVT/PE probability)</li>
<li>eGFR (renal function)</li>
<p>
</ul>
</p>

<strong>Scrape calculator formulas (for reference only, check ToS):</strong>

<pre><code>import requests
<p>
from bs4 import BeautifulSoup
</p>

<p>
def get<em>mdcalc</em>calculators():
    """Get list of MDCalc calculators"""
    url = "https://www.mdcalc.com/sitemap"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
</p>

<p>
    calculators = []
    for link in soup.find_all('a', href=True):
        if '/calc/' in link['href']:
            calculators.append({
                'name': link.text,
                'url': 'https://www.mdcalc.com' + link['href']
            })
</p>

<p>
    return calculators
</code></pre>
</p>

<h4>2. MedCalc</h4>

<strong>URL:</strong> https://www.medcalc.com/
<strong>Content:</strong> Medical statistics calculators

<hr>

<h2>8. Automation Scripts</h2>

<h3>Complete Download Pipeline</h3>

<p>
Create <code>scripts/download<em>all</em>free_resources.sh</code>:
</p>

<pre><code>#!/bin/bash
<h1>Download all free medical resources</h1>

<p>
set -e
</p>

<p>
echo "üöÄ Downloading All Free Medical Resources"
echo "=========================================="
</p>

<h1>Create directory structure</h1>
<p>
mkdir -p data/pdfs/free/{statpearls,ncbi<em>bookshelf,pubmed</em>central,nsw_health,who,openstax}
</p>

<h1>1. StatPearls</h1>
<p>
echo ""
echo "üìö Downloading StatPearls..."
python scripts/download_statpearls.py
</p>

<h1>2. NCBI Bookshelf</h1>
<p>
echo ""
echo "üìñ Downloading NCBI Bookshelf..."
python scripts/download<em>ncbi</em>bookshelf.py
</p>

<h1>3. PubMed Central reviews</h1>
<p>
echo ""
echo "üìÑ Downloading PubMed Central reviews..."
python scripts/download<em>pubmed</em>reviews.py
</p>

<h1>4. NSW Health Guidelines</h1>
<p>
echo ""
echo "üè• Downloading NSW Health Guidelines..."
bash scripts/download<em>nsw</em>guidelines.sh
</p>

<h1>5. Australian Immunisation Handbook</h1>
<p>
echo ""
echo "üíâ Downloading Australian Immunisation Handbook..."
wget -O data/pdfs/free/australian<em>immunisation</em>handbook.pdf \
     https://immunisationhandbook.health.gov.au/resources/handbook
</p>

<h1>6. OpenStax Textbooks</h1>
<p>
echo ""
echo "üìö Downloading OpenStax Medical Books..."
wget -O data/pdfs/free/openstax/anatomy_physiology.pdf \
     https://openstax.org/downloads/anatomy-and-physiology.pdf
wget -O data/pdfs/free/openstax/microbiology.pdf \
     https://openstax.org/downloads/microbiology.pdf
</p>

<p>
echo ""
echo "=========================================="
echo "‚úÖ All Free Resources Downloaded!"
echo "üìÅ Location: data/pdfs/free/"
echo ""
echo "Next steps:"
echo "  1. Run: ./medical_ai.py process all"
echo "  2. Test: ./medical_ai.py test search 'acute coronary syndrome'"
echo "=========================================="
</code></pre>
</p>

<strong>Make executable and run:</strong>
<pre><code>chmod +x scripts/download<em>all</em>free_resources.sh
<p>
./scripts/download<em>all</em>free_resources.sh
</code></pre>
</p>

<hr>

<h2>üìä Estimated Download Sizes</h2>

<p>
| Resource | Articles/Books | Size | Download Time |
|----------|----------------|------|---------------|
| StatPearls | 10,000+ | ~5 GB | 2-4 hours |
| NCBI Bookshelf | 50-100 books | ~2 GB | 1-2 hours |
| PubMed Central | 500 reviews | ~500 MB | 30 min |
| NSW Health | 100 guidelines | ~200 MB | 15 min |
| WHO Guidelines | 50 guidelines | ~300 MB | 20 min |
| OpenStax | 4 books | ~500 MB | 10 min |
| <strong>TOTAL</strong> | <strong>10,000+</strong> | <strong>~8.5 GB</strong> | <strong>4-7 hours</strong> |
</p>

<hr>

<h2>‚úÖ Verification Checklist</h2>

<p>
After downloading, verify you have:
</p>

<pre><code><h1>Check directory structure</h1>
<p>
ls -lh data/pdfs/free/*/
</p>

<h1>Count PDFs</h1>
<p>
find data/pdfs/free -name "*.pdf" | wc -l
</p>
<h1>Should show 1,000+ files</h1>

<h1>Check total size</h1>
<p>
du -sh data/pdfs/free/
</p>
<h1>Should show ~8-10 GB</h1>

<h1>Test a PDF</h1>
<p>
./medical<em>ai.py process pdfs --input data/pdfs/free/statpearls --output data/processed/statpearls</em>test
</p>

<h1>Verify extraction worked</h1>
<p>
ls -lh data/processed/statpearls_test/
</p>
<h1>Should show JSON files with extracted text</h1>
<p>
</code></pre>
</p>

<hr>

<h2>üöÄ Next Steps</h2>

<p>
After downloading free resources:
</p>

<ol>
<li><strong>Process Through Pipeline:</strong></li>
<p>
</ol>
</p>
   <pre><code>   ./medical_ai.py process all
<p>
   </code></pre>
</p>

<ol>
<li><strong>Test Search:</strong></li>
<p>
</ol>
</p>
   <pre><code>   ./medical_ai.py test search "heart failure management"
<p>
   </code></pre>
</p>

<ol>
<li><strong>Generate First Questions:</strong></li>
<p>
</ol>
</p>
   <pre><code>   # Use RAG + LLM to generate test questions
<p>
   # (requires implementing question generation pipeline)
   </code></pre>
</p>

<ol>
<li><strong>Evaluate Quality:</strong></li>
<p>
</ol>
   - Are search results relevant?
   - Is content comprehensive enough?
   - Do generated questions make sense?
</p>

<ol>
<li><strong>Scale or Invest:</strong></li>
<p>
</ol>
   - If quality is good ‚Üí Scale to 5,000+ questions with free content
   - If gaps exist ‚Üí Invest in Australian-specific paid books
</p>

<hr>

<h2>üìû Troubleshooting</h2>

<h3>Problem: Download Speed Too Slow</h3>

<strong>Solution:</strong> Use parallel downloads
<pre><code><h1>Install GNU parallel</h1>
<p>
sudo apt-get install parallel
</p>

<h1>Download StatPearls in parallel (4 concurrent)</h1>
<p>
cat statpearls_urls.txt | parallel -j4 wget -O data/pdfs/free/statpearls/{#}.pdf {}
</code></pre>
</p>

<h3>Problem: NCBI API Rate Limiting</h3>

<strong>Solution:</strong> Add delays
<pre><code>time.sleep(1)  # Wait 1 second between requests
<p>
</code></pre>
</p>

<h3>Problem: PDF Conversion Fails</h3>

<strong>Solution:</strong> Check wkhtmltopdf installation
<pre><code>wkhtmltopdf --version
<h1>If not installed:</h1>
<p>
sudo apt-get install wkhtmltopdf
</code></pre>
</p>

<h3>Problem: Out of Disk Space</h3>

<strong>Solution:</strong> Download selectively
<pre><code><h1>Download only high-priority topics</h1>
<h1>Modify scripts to filter by specialty</h1>
<p>
</code></pre>
</p>

<hr>

<h2>üìö Summary</h2>

<strong>You now have access to:</strong>
<ul>
<li>‚úÖ 10,000+ StatPearls articles</li>
<li>‚úÖ 100+ NCBI Bookshelf books</li>
<li>‚úÖ 500+ PubMed Central reviews</li>
<li>‚úÖ 100+ Australian government guidelines</li>
<li>‚úÖ 50+ WHO guidelines</li>
<li>‚úÖ 4+ OpenStax textbooks</li>
<p>
</ul>
</p>

<strong>Total: 10,000+ medical documents for FREE</strong>

<strong>This is enough to:</strong>
<ul>
<li>Build and test your entire system</li>
<li>Generate 5,000+ practice questions</li>
<li>Create a fully functional medical education platform</li>
<li>Validate your AI pipeline</li>
<p>
</ul>
</p>

<strong>Next:</strong> See <code>REQUIRED_BOOKS.md</code> for when to invest in paid Australian-specific books

<hr>

<strong>Last Updated:</strong> December 14, 2025
<strong>Status:</strong> Ready to download FREE resources and start building today! üöÄ

        
    <div class="footer">
        <p><strong>ICRP Study Project</strong> | NSW Young Hospital Preparation</p>
        <p>Generated: December 15, 2025 at 11:32</p>
        <p><a href="/home/dev/Development/irStudy/MASTER_INDEX.html">Return to Master Index</a></p>
    </div>
    
    </div>
</body>
</html>
